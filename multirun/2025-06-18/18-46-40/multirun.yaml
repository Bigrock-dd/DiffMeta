hydra:
  run:
    dir: outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}
  launcher:
    _target_: hydra._internal.core_plugins.basic_launcher.BasicLauncher
  sweeper:
    _target_: hydra._internal.core_plugins.basic_sweeper.BasicSweeper
    max_batch_size: null
    params: null
  help:
    app_name: ${hydra.job.name}
    header: '${hydra.help.app_name} is powered by Hydra.

      '
    footer: 'Powered by Hydra (https://hydra.cc)

      Use --hydra-help to view Hydra specific help

      '
    template: '${hydra.help.header}

      == Configuration groups ==

      Compose your configuration from those groups (group=option)


      $APP_CONFIG_GROUPS


      == Config ==

      Override anything in the config (foo.bar=value)


      $CONFIG


      ${hydra.help.footer}

      '
  hydra_help:
    template: 'Hydra (${hydra.runtime.version})

      See https://hydra.cc for more info.


      == Flags ==

      $FLAGS_HELP


      == Configuration groups ==

      Compose your configuration from those groups (For example, append hydra/job_logging=disabled
      to command line)


      $HYDRA_CONFIG_GROUPS


      Use ''--cfg hydra'' to Show the Hydra config.

      '
    hydra_help: ???
  hydra_logging:
    version: 1
    formatters:
      simple:
        format: '[%(asctime)s][HYDRA] %(message)s'
    handlers:
      console:
        class: logging.StreamHandler
        formatter: simple
        stream: ext://sys.stdout
    root:
      level: INFO
      handlers:
      - console
    loggers:
      logging_example:
        level: DEBUG
    disable_existing_loggers: false
  job_logging:
    version: 1
    formatters:
      simple:
        format: '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'
    handlers:
      console:
        class: logging.StreamHandler
        formatter: simple
        stream: ext://sys.stdout
      file:
        class: logging.FileHandler
        formatter: simple
        filename: ${hydra.runtime.output_dir}/${hydra.job.name}.log
    root:
      level: INFO
      handlers:
      - console
      - file
    disable_existing_loggers: false
  env: {}
  mode: MULTIRUN
  searchpath: []
  callbacks: {}
  output_subdir: .hydra
  overrides:
    hydra:
    - hydra.mode=MULTIRUN
    task:
    - dataset=moses
    - +experiment=moses_ppo_7W4A.yaml
    - general.train_method=gdpo
    - general.val_method=ppo
    - general.seed=15212
  job:
    name: main_generate
    chdir: null
    override_dirname: +experiment=moses_ppo_7W4A.yaml,dataset=moses,general.seed=15212,general.train_method=gdpo,general.val_method=ppo
    id: ???
    num: ???
    config_name: config
    env_set: {}
    env_copy: []
    config:
      override_dirname:
        kv_sep: '='
        item_sep: ','
        exclude_keys: []
  runtime:
    version: 1.3.2
    version_base: '1.1'
    cwd: /root/autodl-tmp/DiffMeta
    config_sources:
    - path: hydra.conf
      schema: pkg
      provider: hydra
    - path: /root/autodl-tmp/DiffMeta/configs
      schema: file
      provider: main
    - path: ''
      schema: structured
      provider: schema
    output_dir: ???
    choices:
      experiment: moses_ppo_7W4A.yaml
      dataset: moses
      train: train_default
      model: discrete
      general: general_default
      hydra/env: default
      hydra/callbacks: null
      hydra/job_logging: default
      hydra/hydra_logging: default
      hydra/hydra_help: default
      hydra/help: default
      hydra/sweeper: basic
      hydra/launcher: basic
      hydra/output: default
  verbose: false
general:
  name: chembl
  wandb: disabled
  gpus: 1
  device: 0
  seed: 15212
  resume: null
  test_only: null
  check_val_every_n_epochs: 1
  sample_every_val: 1
  test_method: orig
  val_method: ppo
  train_method: gdpo
  ppo_sr: 0.2
  back_step: 50
  chain_L: 5
  innerloop: 2
  sampleloop: 1
  vallike: false
  minibatchnorm: false
  step_freq: 1
  discrete: true
  partial: true
  fix: 0.0
  thres: 0.8
  target_prop: 7W4A
  val_check_interval: 2
  samples_to_generate: 40
  samples_to_save: 9
  chains_to_save: 1
  log_every_steps: 50
  number_chain_steps: 30
  final_model_samples_to_generate: 40
  final_model_samples_to_save: 30
  final_model_chains_to_save: 20
  evaluate_all_checkpoints: false
  remove_h: true
  weight_list:
  - 0.05
  - 0.05
  - 0.05
  - 0.3
  - 0.6
  - 0.05
  - 0.05
model:
  type: discrete
  transition: marginal
  model: graph_tf
  diffusion_steps: 500
  diffusion_noise_schedule: cosine
  n_layers: 12
  extra_features: all
  hidden_mlp_dims:
    X: 256
    E: 128
    'y': 256
  hidden_dims:
    dx: 256
    de: 64
    dy: 128
    n_head: 8
    dim_ffX: 256
    dim_ffE: 128
    dim_ffy: 256
  lambda_train:
  - 5
  - 0
train:
  n_epochs: 100
  batch_size: 128
  lr: 1.0e-05
  clip_grad: null
  save_model: true
  num_workers: 0
  ema_decay: 0
  progress_bar: true
  weight_decay: 1.0e-12
  amsgrad: true
  optimizer: adamw
  seed: 0
dataset:
  name: moses
  datadir: data/moses/moses_pyg/
  remove_h: null
  filter: false
